{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPrfFEBh6NCjCBJmDZAfPEt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<center>\n","<img src=\"https://i.ibb.co/ZVRt2f7/logo.png\" alt=\"logo\" border=\"0\" width=800>\n"],"metadata":{"id":"bB2VgAZdSyGU"}},{"cell_type":"markdown","source":["---\n","## 01. An Image Classification Neural Network\n","\n","\n","Eduard Larrañaga (ealarranaga@unal.edu.co)\n","\n","---"],"metadata":{"id":"1sJXZQswS3Vd"}},{"cell_type":"markdown","source":["### Abstract\n","\n","In this notebook we will train a neural network to classify images.\n","\n","---"],"metadata":{"id":"tCOJ84FdS9ZM"}},{"cell_type":"markdown","source":["---\n","\n","## The Dataset\n","\n","We will use two sets of synthetic images to train and to test a neural network. The training set includes 5000 synthetic images with a size of 28pixels by 28 pixels, showing the solar disk and a random number of 'sunspots' and also includes a set of targets with the number of spots in each image. The test set includes 1000 of images with the corresponding targets. \n"],"metadata":{"id":"sLUz0CMlBOXi"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nyykG6yJQ12","executionInfo":{"status":"ok","timestamp":1668463476980,"user_tz":300,"elapsed":19392,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"9d56330c-a124-413e-bbca-17d3a29292fc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","\n","train_images = np.load(\"/content/drive/MyDrive/Colab Notebooks/Neural Networks/02. Image Classification NN/sun_data/sun_image_train.npy\")\n","train_labels = np.load(\"/content/drive/MyDrive/Colab Notebooks/Neural Networks/02. Image Classification NN/sun_data/sun_label_train.npy\")\n","\n","test_images = np.load(\"/content/drive/MyDrive/Colab Notebooks/Neural Networks/02. Image Classification NN/sun_data/sun_image_test.npy\")\n","test_labels = np.load(\"/content/drive/MyDrive/Colab Notebooks/Neural Networks/02. Image Classification NN/sun_data/sun_label_test.npy\")"],"metadata":{"id":"VNQA3G7Vu4tM","executionInfo":{"status":"ok","timestamp":1668463495363,"user_tz":300,"elapsed":7060,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(train_images.shape)\n","print(train_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGq4-YK3gebC","executionInfo":{"status":"ok","timestamp":1668463499477,"user_tz":300,"elapsed":210,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"ac209683-c225-4526-dc77-1b53dbdde8e5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(5000, 28, 28)\n","(5000,)\n"]}]},{"cell_type":"code","source":["print(test_images.shape)\n","print(test_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdBlDmVLKsFs","executionInfo":{"status":"ok","timestamp":1668463500582,"user_tz":300,"elapsed":5,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"778eeb84-26e2-4510-f48d-a124857e529d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(1000, 28, 28)\n","(1000,)\n"]}]},{"cell_type":"markdown","source":["These images are already 'normalized', i.e. the entries in the array are numbers in the range [0,1],"],"metadata":{"id":"oRnoE127LAGo"}},{"cell_type":"code","source":["train_images[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1D3YqTN6LN22","executionInfo":{"status":"ok","timestamp":1668463504775,"user_tz":300,"elapsed":249,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"b61f2e22-c92b-45fb-efec-2cb2597e3736"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n","        0.6       , 0.6       , 0.6       , 0.6       , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.6       , 0.6       ,\n","        0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n","        0.8       , 0.8       , 0.8       , 0.8       , 0.6       ,\n","        0.6       , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.6       , 0.8       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.8       , 0.6       , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.6       , 0.8       , 0.8       , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.97246874,\n","        0.99437585, 0.60860347, 1.        , 1.        , 1.        ,\n","        0.8       , 0.8       , 0.6       , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.6       , 0.8       , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.92930387,\n","        0.        , 0.86470304, 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 0.8       , 0.6       , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.6       ,\n","        0.8       , 0.8       , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.87020561,\n","        0.65751838, 0.72141356, 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 0.8       , 0.8       , 0.6       ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.6       ,\n","        0.8       , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 0.8       , 0.6       ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.6       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 0.8       ,\n","        0.6       , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.6       ,\n","        0.8       , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 0.8       , 0.6       ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.6       ,\n","        0.8       , 0.8       , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 0.8       , 0.8       , 0.6       ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.6       , 0.8       , 1.        , 1.        , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 0.86238115, 0.99121399, 0.75368378, 1.        ,\n","        1.        , 1.        , 0.8       , 0.6       , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.6       , 0.8       , 0.8       , 1.        ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 0.63733299, 0.        , 0.64097163, 1.        ,\n","        0.8       , 0.8       , 0.6       , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.6       , 0.8       , 0.8       ,\n","        1.        , 1.        , 1.        , 1.        , 1.        ,\n","        1.        , 0.8824508 , 0.83775334, 0.5466085 , 0.8       ,\n","        0.8       , 0.6       , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.6       , 0.6       ,\n","        0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n","        0.8       , 0.8       , 0.8       , 0.8       , 0.6       ,\n","        0.6       , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n","        0.6       , 0.6       , 0.6       , 0.6       , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["We can visualize some of the images in the trining set,"],"metadata":{"id":"ZBxviEp8Kv_5"}},{"cell_type":"code","source":["fig, ax = plt.subplots(1,7, figsize=(15,7))\n","\n","for i in range(7):    \n","    ax[i].imshow(train_images[i+5], cmap='gray')\n","    ax[i].set_xticks([])\n","    ax[i].set_yticks([])\n","    ax[i].set_xlabel(f'Number of sunspots : {train_labels[i+5]:.0f}')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"id":"Sjk_L8BGKjCU","executionInfo":{"status":"ok","timestamp":1668463534438,"user_tz":300,"elapsed":1042,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"acac1ba9-df8d-45e3-e05c-b72e99ff04d4"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x504 with 7 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["def showImage(x,y,item):\n","  plt.figure()\n","  plt.imshow(x[item], cmap='gray')\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.xlabel(f'Number of sunspots : {y[item]:.0f}')\n","  plt.show()\n","\n","\n","showImage(train_images, train_labels, 2557)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"X8HF6JXTH7F8","executionInfo":{"status":"ok","timestamp":1668463540884,"user_tz":300,"elapsed":468,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"b400db09-9ef2-4905-fff8-9b993d86fdbc"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## The Classification Neural Network\n","\n","We want to train a neural network model that reads the data and classify these images according to the number of stars (targets). Therefore we need to declare the following:\n","\n","- An input layer that reads the data in the image. This will be a 'Flatten' layer (it will take the image of size 28 by 28 and will convert it into a flat array with 784 entries). Therefore, we need 784 neurons in this layer.\n","\n","- We will use 2 hidden dense layer with 50 neurons and a ReLU activation (ReLU will ignore negative values)\n","\n","- Finally we will incorporate an output dense layer with 6 neurons (because the number of stars in the set goes from 0 to 5) and a 'softmax' activation function.\n","\n","- The model will be a 'Sequential' neural network."],"metadata":{"id":"_d5apPDlLYvg"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","\n","# input layer: Type Flatten. The input is an image of 28x28 pixels with 1 channel\n","inputlyr = tf.keras.layers.Flatten(input_shape=(28,28,1))\n","\n","# hidden layers with 50 neurons and relu\n","hdnlyr01 = tf.keras.layers.Dense(units=50, activation=tf.nn.relu)\n","hdnlyr02 = tf.keras.layers.Dense(units=50, activation=tf.nn.relu)\n","\n","# output layer\n","outlyr = tf.keras.layers.Dense(units=6, activation=tf.nn.softmax)\n","\n","\n","model = tf.keras.Sequential([inputlyr, hdnlyr01, hdnlyr02, outlyr])\n"],"metadata":{"id":"4iRc3G6PPlre","executionInfo":{"status":"ok","timestamp":1668463548735,"user_tz":300,"elapsed":483,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["In order to compile the neural network we will include the [ADAM](https://keras.io/api/optimizers/adam/) optimizer, the [SparseCategoricalCrossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class) loss function and the [accuracy](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class) metric."],"metadata":{"id":"fpfPb6iQMrDL"}},{"cell_type":"code","source":["model.compile(\n","    optimizer = tf.keras.optimizers.Adam(),\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"5hIear72ytiq","executionInfo":{"status":"ok","timestamp":1668463553369,"user_tz":300,"elapsed":252,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### The CategoricalCrossentropy and the SparseCategoricalCrossentropy loss functions \n","\n","The [CategoricalCrossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class) and the [SparseCategoricalCrossentropy](https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class) loss functions are used to measure the  cost of a classification model.\n","\n","In order to use these function, the algorithm may use and encoding to represent the targets. For example, if one has some categorical targets, they are first represented as integer values:\n","\n","- TargetA ---> 0 \n","- TargetB ---> 1\n","- TargetC ---> 2\n","- TargetD ---> 3\n","...\n","\n","Under this encoding, we can use the 'sparsecategorical_crossentropy' function which is defined as\n","\n","\\begin{equation}\n","J(w) = -\\sum_{i=1}^N y_i\\log (y_i^p) \n","\\end{equation}\n","\n","\n","\n","Another representation is obtained by using the **one-hot encoding**, which is based on the use of binary vectors. In this case each integer assigned to the categorical targets is represented as a binary vector, that is all zero values except the index of the integer which is marked with a 1. For example:\n","\n","- TargetA ---> 0  ---> [1 0 0 0]\n","- TargetB ---> 1  ---> [0 1 0 0]\n","- TargetC ---> 2  ---> [0 0 1 0]\n","- TargetD ---> 3  ---> [0 0 0 1]\n","...\n","\n","Under this encoding, we can use the 'categorical_crossentropy' function which is defined as before\n","\n","\\begin{equation}\n","J(w) = -\\sum_{i=1}^N y_i \\log (y_i^p) \n","\\end{equation}\n"],"metadata":{"id":"JG8S5WKV_hun"}},{"cell_type":"markdown","source":["\n","\n","### Metrics\n","\n","A metric is a function that is used to judge the performance of the model.\n","\n","Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model (In fact, one can use any loss function as a metric).\n","\n","Keras includes many [metrics](https://keras.io/api/metrics/):\n","\n","**Accuracy metrics**\n","- Accuracy class\n","- BinaryAccuracy class\n","- CategoricalAccuracy class\n","- SparseCategoricalAccuracy class\n","- TopKCategoricalAccuracy class\n","- SparseTopKCategoricalAccuracy class\n","\n","**Probabilistic metrics**\n","- BinaryCrossentropy class\n","- CategoricalCrossentropy class\n","- SparseCategoricalCrossentropy class\n","- KLDivergence class\n","- Poisson class\n","\n","**Regression metrics**\n","- MeanSquaredError class\n","- RootMeanSquaredError class\n","- MeanAbsoluteError class\n","- MeanAbsolutePercentageError class\n","- MeanSquaredLogarithmicError class\n","- CosineSimilarity class\n","- LogCoshError class\n","\n","**Classification metrics based on True/False positives & negatives**\n","- AUC class\n","- Precision class\n","- Recall class\n","- TruePositives class\n","- TrueNegatives class\n","- FalsePositives class\n","- FalseNegatives class\n","- PrecisionAtRecall class\n","- SensitivityAtSpecificity class\n","- SpecificityAtSensitivity class\n","- Image segmentation metrics\n","- MeanIoU class\n","- Hinge metrics for \"maximum-margin\" classification\n","- Hinge class\n","- SquaredHinge class\n","- CategoricalHinge class"],"metadata":{"id":"uw1eiKCK-9yW"}},{"cell_type":"code","source":["# print model summary before training\n","model.summary()"],"metadata":{"id":"DqB3pBWycASs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668463563281,"user_tz":300,"elapsed":200,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"a7dce0aa-8deb-4b6e-e289-73001dbc840d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense (Dense)               (None, 50)                39250     \n","                                                                 \n"," dense_1 (Dense)             (None, 50)                2550      \n","                                                                 \n"," dense_2 (Dense)             (None, 6)                 306       \n","                                                                 \n","=================================================================\n","Total params: 42,106\n","Trainable params: 42,106\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Now we will train the model using the train-sets and 5 epochs."],"metadata":{"id":"ZfwiwAyvM7_s"}},{"cell_type":"code","source":["history = model.fit(train_images, train_labels, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKhmMuV44Ugo","executionInfo":{"status":"ok","timestamp":1668463635950,"user_tz":300,"elapsed":41525,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"45bb01f5-c168-4792-be12-47901159570d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","157/157 [==============================] - 1s 6ms/step - loss: 1.7916 - accuracy: 0.1702\n","Epoch 2/100\n","157/157 [==============================] - 1s 3ms/step - loss: 1.7917 - accuracy: 0.1702\n","Epoch 3/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1606\n","Epoch 4/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1696\n","Epoch 5/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1632\n","Epoch 6/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1650\n","Epoch 7/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1674\n","Epoch 8/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1632\n","Epoch 9/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1628\n","Epoch 10/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1598\n","Epoch 11/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1656\n","Epoch 12/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1622\n","Epoch 13/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1694\n","Epoch 14/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1560\n","Epoch 15/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1638\n","Epoch 16/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1640\n","Epoch 17/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1566\n","Epoch 18/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1702\n","Epoch 19/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1632\n","Epoch 20/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1608\n","Epoch 21/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1660\n","Epoch 22/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1686\n","Epoch 23/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1648\n","Epoch 24/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1678\n","Epoch 25/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1702\n","Epoch 26/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1706\n","Epoch 27/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1640\n","Epoch 28/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1696\n","Epoch 29/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1670\n","Epoch 30/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1672\n","Epoch 31/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1654\n","Epoch 32/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1690\n","Epoch 33/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1666\n","Epoch 34/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1620\n","Epoch 35/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1656\n","Epoch 36/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1628\n","Epoch 37/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1666\n","Epoch 38/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1604\n","Epoch 39/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1586\n","Epoch 40/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1684\n","Epoch 41/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1672\n","Epoch 42/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1600\n","Epoch 43/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1638\n","Epoch 44/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1626\n","Epoch 45/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1644\n","Epoch 46/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1608\n","Epoch 47/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1638\n","Epoch 48/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1702\n","Epoch 49/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1636\n","Epoch 50/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1632\n","Epoch 51/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1602\n","Epoch 52/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1674\n","Epoch 53/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1694\n","Epoch 54/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1618\n","Epoch 55/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1630\n","Epoch 56/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1578\n","Epoch 57/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1666\n","Epoch 58/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1644\n","Epoch 59/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1702\n","Epoch 60/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1666\n","Epoch 61/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1636\n","Epoch 62/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1670\n","Epoch 63/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1702\n","Epoch 64/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1660\n","Epoch 65/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1666\n","Epoch 66/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1638\n","Epoch 67/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1658\n","Epoch 68/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1668\n","Epoch 69/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1636\n","Epoch 70/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1558\n","Epoch 71/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1570\n","Epoch 72/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1624\n","Epoch 73/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1616\n","Epoch 74/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1632\n","Epoch 75/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1664\n","Epoch 76/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1618\n","Epoch 77/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1678\n","Epoch 78/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1662\n","Epoch 79/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1620\n","Epoch 80/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1680\n","Epoch 81/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1652\n","Epoch 82/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1660\n","Epoch 83/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1652\n","Epoch 84/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1658\n","Epoch 85/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1644\n","Epoch 86/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1632\n","Epoch 87/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1616\n","Epoch 88/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1614\n","Epoch 89/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1680\n","Epoch 90/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1588\n","Epoch 91/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1702\n","Epoch 92/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1648\n","Epoch 93/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1596\n","Epoch 94/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1660\n","Epoch 95/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1602\n","Epoch 96/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1616\n","Epoch 97/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1678\n","Epoch 98/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1702\n","Epoch 99/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7916 - accuracy: 0.1638\n","Epoch 100/100\n","157/157 [==============================] - 0s 2ms/step - loss: 1.7917 - accuracy: 0.1656\n"]}]},{"cell_type":"markdown","source":["Note that the training gives an accuracy (with the training set) of 0.1656 and a final cost function fo 1.7917"],"metadata":{"id":"eikQyAevamKP"}},{"cell_type":"markdown","source":["---\n","## Testing the Model\n","\n","Now we will use the test subsets to probe the model. Using the '.evaluate()' method, we obtain the accuracy of the model (using the metric defined above),"],"metadata":{"id":"ydSWhoQxgqx_"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n","\n","print('\\nTest accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWufSHITNZKs","executionInfo":{"status":"ok","timestamp":1668463635951,"user_tz":300,"elapsed":6,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"63b64579-1e11-41e3-c29a-9cb7599a128a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 - 0s - loss: 1.7917 - accuracy: 0.1700 - 208ms/epoch - 7ms/step\n","\n","Test accuracy: 0.17000000178813934\n"]}]},{"cell_type":"markdown","source":["Note that the trained model have an accuracy of only 0.17 on the test set.\n","\n","Using the '.predict()' method we will obtain the predictions for the test set,"],"metadata":{"id":"wXK9nA5WhPpZ"}},{"cell_type":"code","source":["predictions= model.predict(test_images)"],"metadata":{"id":"GskOfRL7vuaE","executionInfo":{"status":"ok","timestamp":1668463645114,"user_tz":300,"elapsed":476,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"185d6850-70ee-4c8f-d826-c61dc4a8f65b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 0s 1ms/step\n"]}]},{"cell_type":"markdown","source":["The result for a particular sample is a collection of probabilities associated with each of the possible targets (number of stars from 0 to 5),"],"metadata":{"id":"os5tZ7M7hwAN"}},{"cell_type":"code","source":["predictions[18]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLs6ezc9h_Fj","executionInfo":{"status":"ok","timestamp":1668463648208,"user_tz":300,"elapsed":205,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"3ef94e99-367b-4f7a-89b0-2c31124660bc"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.15954697, 0.17017612, 0.16937001, 0.16963275, 0.16894609,\n","       0.16232806], dtype=float32)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["Since we use the activation function 'softmax' in the output layer, the sum of all the probabilities for a single sample is 1,"],"metadata":{"id":"Cx2hRoO6hkMa"}},{"cell_type":"code","source":["sum(predictions[18])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1avjpMJhaUr","executionInfo":{"status":"ok","timestamp":1668463651267,"user_tz":300,"elapsed":384,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"428aad7c-7165-479f-dd9e-d94378d660e4"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["Using the function 'np.argmax()' we obtain the index corresponding to the maximum probability,"],"metadata":{"id":"Lzl9ib2niNgi"}},{"cell_type":"code","source":["np.argmax(predictions[18])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcYQ2WhthdO0","executionInfo":{"status":"ok","timestamp":1668463653644,"user_tz":300,"elapsed":219,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"8233275f-cf4c-4ee5-b462-4b672fc491e1"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["---\n","## Visualization of the Results\n","\n","In order to visualize the result of the mode, we define two plotting functions. The first one shows the image together with the predicted value. The second one shows the probabilities of all the targets for the given sample."],"metadata":{"id":"aMBGHGNFjTTO"}},{"cell_type":"code","source":["def plot_image(i, p=predictions, tar = test_labels, image = test_images):\n","  target, img = tar[i], image[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.imshow(img, cmap='gray')\n","\n","  pred_target = np.argmax(p[i])\n","  if pred_target == target:\n","    color = 'blue'\n","  else:\n","    color = 'red'\n","\n","  plt.xlabel(\"Predicted: {} ({:2.0f}%)   True:{}\".format(pred_target,\n","                                100*np.max(p),\n","                                target),\n","                                color=color)\n","\n","def plot_value_array(i, p=predictions, tar = test_labels):\n","  target = tar[i]\n","  #plt.grid(False)\n","  plt.xticks(range(6))\n","  plt.yticks([])\n","  thisplot = plt.bar(range(6), p[i], color=\"#777777\")\n","  plt.ylim([0, 1])\n","  pred_target = np.argmax(p[i])\n","\n","  thisplot[pred_target].set_color('red')\n","  thisplot[target].set_color('blue')"],"metadata":{"id":"jss5fU9gckwb","executionInfo":{"status":"ok","timestamp":1668463658229,"user_tz":300,"elapsed":206,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["i = 550\n","\n","plt.figure(figsize=(10,4))\n","plt.subplot(1,2,1)\n","plot_image(i)\n","plt.subplot(1,2,2)\n","plot_value_array(i)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"AvmpNylwc0PV","executionInfo":{"status":"ok","timestamp":1668463733191,"user_tz":300,"elapsed":864,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"85ceef44-1285-4a86-f2fb-d67b098a1424"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[],"metadata":{"id":"IlLCMLDb5YaT"},"execution_count":null,"outputs":[]}]}